<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="Dichotomous Diffusion Policy Optimization">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="reinforcement learning, diffusion model, autonomous driving, robotics">
  <!-- TODO: List all authors -->
  <meta name="author"
    content="Ruiming Liang, Yinan Zheng, Kexin Zheng, Tianyi Tan, Jianxiong Li, Liyuan Mao, Zhihao Wang, Guang Chen, Hangjun Ye, Jingjing Liu, Jinqiao Wang, Xianyuan Zhan">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">

  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>Dichotomous Diffusion Policy Optimization - Ruiming Liang, et.al. | Academic Research
  </title>

  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="page/images/favicon.ico">
  <link rel="apple-touch-icon" href="page/images/favicon.ico">

  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="page/css/bulma.min.css">
  <link rel="stylesheet" href="page/css/index.css">

  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="page/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="page/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="page/css/fontawesome.all.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">

  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="page/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="page/css/bulma-slider.min.css">
    <link rel="stylesheet" href="page/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>

  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">

  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="page/js/fontawesome.all.min.js"></script>
  <script defer src="page/js/bulma-carousel.min.js"></script>
  <script defer src="page/js/bulma-slider.min.js"></script>
  <script defer src="page/js/index.js"></script>
</head>

<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <!-- More Works Dropdown -->
  <div class="more-works-container" style="visibility: hidden;">
    <button class="more-works-btn" onclick="toggleMoreWorks()" title="View More Works from Our Lab">
      <i class="fas fa-flask"></i>
      More Works
      <i class="fas fa-chevron-down dropdown-arrow"></i>
    </button>
    <div class="more-works-dropdown" id="moreWorksDropdown">
      <div class="dropdown-header">
        <h4>More Works from Our Lab</h4>
        <button class="close-btn" onclick="toggleMoreWorks()">
          <i class="fas fa-times"></i>
        </button>
      </div>
      <div class="works-list">
        <!-- TODO: Replace with your lab's related works -->
        <a href="https://arxiv.org/abs/PAPER_ID_1" class="work-item" target="_blank">
          <div class="work-info">
            <!-- TODO: Replace with actual paper title -->
            <h5>Paper Title 1</h5>
            <!-- TODO: Replace with brief description -->
            <p>Brief description of the work and its main contribution.</p>
            <!-- TODO: Replace with venue and year -->
            <span class="work-venue">Conference/Journal 2024</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <!-- TODO: Add more related works or remove extra items -->
        <a href="https://arxiv.org/abs/PAPER_ID_2" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Paper Title 2</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2023</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://arxiv.org/abs/PAPER_ID_3" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Paper Title 3</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2023</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
      </div>
    </div>
  </div>

  <main id="main-content">
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">Dichotomous Diffusion Policy Optimization</h1>

              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <a href="https://github.com/LRMbbj" target="_blank">Ruiming Liang</a><sup>1,2 * &Dagger;</sup>,</span>
                <span class="author-block">
                  <a href="https://github.com/ZhengYinan-AIR" target="_blank">Yinan Zheng</a><sup>3 *
                    &para;</sup>,</span>
                <span class="author-block">
                  <a href="https://github.com/Whiterrrrr" target="_blank">Kexin Zheng</a><sup>4 * &Dagger;</sup>,</span>
                <span class="author-block">
                  <a href="https://github.com/0ttwhy4" target="_blank">Tianyi Tan</a><sup>3 *</sup>,</span>
                <span class="author-block">
                  <a href="https://facebear-ljx.github.io/" target="_blank">Jianxiong Li</a><sup>3</sup>,</span>
                <span class="author-block">
                  <a href="" target="_blank">Liyuan Mao</a><sup>5</sup>,</span>
                <span class="author-block">
                  <a href="https://zh1hao.wang/" target="_blank">Zhihao Wang</a><sup>6</sup>,</span>
                <span class="author-block">
                  <a href="" target="_blank">Guang Chen</a><sup>7</sup>,</span>
                <span class="author-block">
                  <a href="" target="_blank">Hangjun Ye</a><sup>7</sup>,</span>
                <span class="author-block">
                  <a href="https://air.tsinghua.edu.cn/en/info/1046/1194.htm" target="_blank">Jingjing
                    Liu</a><sup>3</sup>,</span>
                <span class="author-block">
                  <a href="" target="_blank">Jinqiao Wang</a><sup>1,2 &dagger;</sup>,</span>
                <span class="author-block">
                  <a href="https://zhanxianyuan.xyz/" target="_blank">Xianyuan Zhan</a><sup>3 &dagger;</sup>
                </span>
              </div>

              <div class="is-size-5 publication-authors">
                <!-- TODO: Replace with your institution and conference/journal info -->
                <!-- 1 Fundation Model Research Center, Institute of Automation, Chinese Academy of Sciences
                2 School of Artificial Intelligence, University of Chinese Academy of Sciences
                3 Institute for AI Industry Research (AIR), Tsinghua University
                4 The Chinese University of Hong Kong 5 Shanghai Jiao Tong University
                6 Peking University 7 Xiaomi EV -->
                <span class="author-block">
                  <sup>1</sup>Fundation Model Research Center, Institute of Automation, Chinese Academy of Sciences,<br>
                  <sup>2</sup>School of Artificial Intelligence, University of Chinese Academy of Sciences,<br>
                  <sup>3</sup>Institute for AI Industry Research (AIR), Tsinghua University, <br>
                  <sup>4</sup>The Chinese University of Hong Kong,
                  <sup>5</sup>Shanghai Jiao Tong University,
                  <sup>6</sup>Peking University,
                  <sup>7</sup>Xiaomi EV
                  <br><br>Under Review</span>
                <!-- TODO: Remove this line if no equal contribution -->
                <span class="eql-cntrb"><small><br>
                    <sup>*</sup>Equal Contribution.
                    <sup>&dagger;</sup>Corresponding Author.
                    <sup>&Dagger;</sup>Work done during internships.
                    <sup>&para;</sup>Project lead.
                </span>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- TODO: Update with your arXiv paper ID -->
                  <span class="link-block">
                    <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>

                  <!-- TODO: Add your supplementary material PDF or remove this section -->
                  <!-- <span class="link-block">
                    <a href="page/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- TODO: Replace with your GitHub repository URL -->
                  <span class="link-block">
                    <a href="https://github.com/LRMbbj/DIPOLE" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>

                  <!-- TODO: Update with your arXiv paper ID -->
                  <!-- <span class="link-block">
                    <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span> -->
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>


    <!-- Teaser video-->
    <section class="hero teaser is-small">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <!-- SVG -->
          <div class="video-container">
            <img src="page/images/method.svg" alt="SVG Image">

            <h2 class="subtitle has-text-centered">
              DIPOLE algorithm overview
            </h2>
          </div>
        </div>
    </section>
    <!-- End teaser video -->

    <!-- Paper abstract -->
    <!-- <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                Diffusion-based policies have gained growing popularity in solving a wide range of decision-making tasks
                due to their superior expressiveness and controllable generation during inference. However, effectively
                training large diffusion policies using reinforcement learning (RL) remains challenging. Existing
                methods either suffer from unstable training due to directly maximizing value objectives, or face
                computational issues due to relying on crude Gaussian likelihood approximation, which requires a large
                amount of sufficiently small denoising steps. In this work, we propose DIPOLE (Dichotomous diffusion
                Policy improvement), a novel RL algorithm designed for stable and controllable diffusion policy
                optimization. We begin by revisiting the KL-regularized objective in RL, which offers a desirable
                weighted regression objective for diffusion policy extraction, but often struggles to balance greediness
                and stability. We then formulate a greedified policy regularization scheme, which naturally enables
                decomposing the optimal policy into a pair of stably learned dichotomous policies: one aims at reward
                maximization, and the other focuses on reward minimization. Under such a design, optimized actions can
                be generated by linearly combining the scores of dichotomous policies during inference, thereby enabling
                flexible control over the level of greediness.Evaluations in offline and offline-to-online RL settings
                on ExORL and OGBench demonstrate the effectiveness of our approach. We also use DIPOLE to train a large
                vision-language-action (VLA) model for end-to-end autonomous driving (AD) and evaluate it on the
                large-scale real-world AD benchmark NAVSIM, highlighting its potential for complex real-world
                applications.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section> -->
    <!-- End paper abstract -->

    <!-- Paper abstract -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full">
            <h2 class="title is-3">Takeaways</h2>
            <div class="content">
              <!-- TODO: Replace with your paper abstract -->
              <p>
                ‚≠êÔ∏è <b>Stability:</b> Splits the unstable exponential weighting into two bounded components, enabling
                stable
                diffusion-policy learning.
              </p>
              <p>
                ‚≠êÔ∏è <b>Controllability:</b> Reconstructs the final policy via a linear combination of the two dichotomous
                policies‚Äô scores, yielding CFG-like greediness control with a single knob œâ.
              </p>
              <p>
                ‚≠êÔ∏è <b>Scalability:</b> Outperforms strong baselines across offline, offline-to-online, and large-scale
                Vision-Language-Action tasks.
              </p>
              <p></p>
              <p>
                <b>DIPOLE</b> is a reinforcement learning framework for <b>stable</b>, <b>controllable</b>, and
                <b>scalable</b> optimization of diffusion policies. It reformulates KL-regularized RL and decomposes
                policy improvement into a pair of dichotomous diffusion policies, enabling precise control over policy
                optimality at inference time while maintaining stable training dynamics.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End paper abstract -->

    <section class="section hero is-small">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full">
            <div class="content">
              <h2 class="title is-3">Method</h2>
              <h3>üîÄ Stable Training</h3>
              <p>
                DIPOLE represents the optimal policy as a combination of two diffusion policies,
                each trained with <strong>stable, bounded sigmoid-weighted regression</strong>.
              </p>

              <div style="display: flex; gap: 2rem; margin: 1.5rem 0; flex-wrap: wrap;">
                <div style="flex: 1; min-width: 260px; padding: 1rem; border-radius: 12px; background: #f7f7f7;">
                  <h4>Positive Policy (œÄ‚Å∫)</h4>
                  <p>
                    Encouraged toward <strong>high-reward actions</strong>,
                    capturing behaviors preferred by the reward signal.
                  </p>
                </div>

                <div style="flex: 1; min-width: 260px; padding: 1rem; border-radius: 12px; background: #f7f7f7;">
                  <h4>Negative Policy (œÄ‚Åª)</h4>
                  <p>
                    Discouraged toward <strong>low-reward actions</strong>,
                    stabilizing learning by explicitly modeling undesirable behaviors.
                  </p>
                </div>
              </div>

              <p>
                This <em>dichotomous decomposition</em> avoids exponential loss explosion and enables
                efficient learning from both high- and low-quality data.
              </p>

              <hr style="margin: 2rem 0;">

              <h3>üéõÔ∏è CFG-style Controllable Inference</h3>

              <p>
                At inference time, DIPOLE reconstructs the final policy by
                <strong>linearly combining the scores</strong> of the two diffusion policies
                in a <em>Classifier-Free-Guidance (CFG)</em>‚Äìstyle manner:
              </p>

              <div style="text-align: center; margin: 1.5rem 0; font-size: 1.1rem;">
                <code>
      Œµ = (1 + œâ) ¬∑ Œµ<sup>+</sup> ‚àí œâ ¬∑ Œµ<sup>‚àí</sup>
    </code>
              </div>

              <p>
                The greediness factor <strong>œâ</strong> acts as a
                <strong>continuous and interpretable control knob</strong>,
                smoothly interpolating between:
              </p>

              <ul>
                <li><strong>œâ = 0</strong>: conservative, sigmoid-weighted-like behavior</li>
                <li><strong>larger œâ</strong>: increasingly greedy, higher-reward behavior</li>
              </ul>
              <hr style="margin: 2rem 0;">
              <h3>ü§ñ Algorithm</h3>
              <img src="page/images/algo.png" alt="DIPOLE Algorithm" />
            </div>
          </div>
        </div>
      </div>

    </section>

    <section class="section hero is-light is-small">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full">
            <div class="content">
              <h2 class="title is-3">Experiment</h2>
              <div>
                <h3 class="title is-4">Representative Tasks</h3>
                <p>
                </p>
                <div class="video-container">
                  <video class="center-block" width="24%" autoplay="" loop="" muted="" playsinline="">
                    <source
                      src="page/videos/dipole_demo/antsoccer-arena-navigate-singletask-task1-v0_evaluation_cfg1.5_ep5.mp4"
                      type="video/mp4">
                  </video>
                  <!-- caption -->
                  <video class="center-block" width="24%" autoplay="" loop="" muted="" playsinline="">
                    <source src="page/videos/dipole_demo/cube-double-play-singletask-task2-v0_evaluation_cfg1.5_ep1.mp4"
                      type="video/mp4">
                  </video>
                  <video class="center-block" width="24%" autoplay="" loop="" muted="" playsinline="">
                    <source
                      src="page/videos/dipole_demo/humanoidmaze-large-navigate-singletask-task1-v0_evaluation_cfg1.5_ep0.mp4"
                      type="video/mp4">
                  </video>
                  <video class="center-block" width="24%" autoplay="" loop="" muted="" playsinline="">
                    <source src="page/videos/dipole_demo/exorl_walker_walk_cfg5.0.mp4" type="video/mp4">
                  </video>
                  <p class="subtitle has-text-centered">
                    Some representative cases of RL benchmarks.
                  </p>
                  <br>
                </div>
                <p></p>
                <div class="image-container">
                  <img src="page/images/dpvla_demo/2f5ae1e4cf9d59fa_page-0001.jpg" width="24%"
                    alt="Autonomous Driving Demo">
                  <img src="page/images/dpvla_demo/a59bd481d324594a_page-0001.jpg" width="24%"
                    alt="Autonomous Driving Demo">
                  <img src="page/images/dpvla_demo/a815da9bf45d5b15_page-0001.jpg" width="24%"
                    alt="Autonomous Driving Demo">
                  <img src="page/images/dpvla_demo/b72ed3ae0ad551a8_page-0001.jpg" width="24%"
                    alt="Autonomous Driving Demo">
                  <p class="subtitle has-text-centered">
                    Some representative cases of autonomous driving.
                  </p>
                  <br>
                </div>
              </div>
              <br>
              <br>
              <div>
                <h3 class="title is-4">Quantitative Results</h3>
                <p>
                </p>

                <div class="columns is-centered">
                  <img src="page/images/exorl.png" alt="ExORL Results">
                </div>
                <p class="subtitle has-text-centered">
                  ExORL Results. We report the average score over 8 random seeds. DIPOLE achieves the best
                  performance.
                </p>
                <br>

                <div class="columns is-centered">
                  <img src="page/images/ogbench.png" alt="OGBench Results">
                </div>
                <p class="subtitle has-text-centered">
                  OGBench Results. We report the aggregate score on all single tasks for each category, averaging over
                  8 random seeds.
                </p>
                <br>

                <div class="columns is-centered">
                  <img src="page/images/ogbench_o2o.png" alt="OGBench Offline-to-Online Results">
                </div>
                <p class="subtitle has-text-centered">
                  OGBench Offline-to-Online Results. We report the score on the default task for each category,
                  averaging over 8 random seeds. (humanoidmaze-m: humanoidmaze-medium-navigate)
                </p>
                <br>

                <div class="columns is-centered">
                  <img src="page/images/navsim.png" alt="NAVSIM Closed-Loop Results">
                </div>
                <p class="subtitle has-text-centered">
                  NAVSIM Closed-Loop Results. We scale up DIPOLE to a large VLA model, demonstrating its
                  potential for real-world applications. (navtrain/navtest represent different data splits used for
                  trajectory rollout)
                </p>

              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!--BibTex citation -->
    <section class="section is-light" id="BibTeX">
      <div class="container is-max-desktop content">
        <div class="bibtex-header">
          <h2 class="title">BibTeX</h2>
          <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
            <i class="fas fa-copy"></i>
            <span class="copy-text">Copy</span>
          </button>
        </div>
        <pre id="bibtex-code"><code>
          @article{liang2026dipole,
            title={Dichotomous Diffusion Policy Optimization},
            author={Ruiming Liang and Yinan Zheng and Kexin Zheng and Tianyi Tan and Jianxiong Li and Liyuan Mao and Zhihao Wang and Guang Chen and Hangjun Ye and Jingjing Liu and Jinqiao Wang and Xianyuan Zhan},
            journal={arXiv preprint arXiv:2601.00898},
            year={2026}
          }
        </code></pre>
      </div>
    </section>
    <!--End BibTex citation -->


    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">

              <p>
                This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                  target="_blank">Academic Project Page Template</a> which was adopted from the¬†<a
                  href="https://nerfies.github.io" target="_blank">Nerfies</a>¬†project page.
                You are free to borrow the source code of this website, we just ask that you link back to this page in
                the footer. <br> This website is licensed under a <a rel="license"
                  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                  Commons Attribution-ShareAlike 4.0 International License</a>.
              </p>

            </div>
          </div>
        </div>
      </div>
    </footer>

    <!-- Statcounter tracking code -->

    <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

</body>

</html>
